{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc78dd0a-20c4-4b5b-9623-8d2f55486e96",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f98db-5838-49b2-923e-f288fc2ba96f",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f6822-07d1-479c-9f78-647d30293519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from textwrap import dedent\n",
    "\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import psycopg\n",
    "from germanetpy.filterconfig import Filterconfig\n",
    "from germanetpy.frames import Frames\n",
    "from germanetpy.germanet import Germanet\n",
    "from germanetpy.path_based_relatedness_measures import PathBasedRelatedness\n",
    "from germanetpy.synset import WordCategory, WordClass\n",
    "from psycopg.sql import SQL, Identifier, Literal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc713881-9f62-4df9-89ca-1169916e3d79",
   "metadata": {},
   "source": [
    "## global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49acbdb7-7e78-4bad-9386-4b5e920bb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_TEST = True\n",
    "pio.renderers.default = \"notebook\"\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a65b7-42d4-4ef0-bb43-a9e12fb7ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "germanet = Germanet(\"/veld/input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf64211-2176-421c-8304-0fbfa07845ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\")\n",
    "POSTGRES_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "POSTGRES_DB = os.getenv(\"POSTGRES_DB\")\n",
    "print(f\"{POSTGRES_HOST=}\")\n",
    "print(f\"{POSTGRES_PORT=}\")\n",
    "print(f\"{POSTGRES_USER=}\")\n",
    "print(f\"{POSTGRES_PASSWORD=}\")\n",
    "print(f\"{POSTGRES_DB=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e35395-5d59-4e87-b900-d04a8907ea0d",
   "metadata": {},
   "source": [
    "## DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faa63f8-4a9e-483a-b089-22d6fd63b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    host=POSTGRES_HOST,\n",
    "    port=POSTGRES_PORT,\n",
    "    dbname=POSTGRES_DB,\n",
    "    user=POSTGRES_USER,\n",
    "    password=POSTGRES_PASSWORD,\n",
    ")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT version()\")\n",
    "print(cursor.fetchone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3131eb1-2fdd-4143-816f-48f5d926326c",
   "metadata": {},
   "source": [
    "# individual functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027577d0-9489-4d0f-8488-52461440980b",
   "metadata": {},
   "source": [
    "### print_sample_of_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c265e-9e31-4593-b8b3-6ef1926d693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_of_related(word_sim_dict, num_steps):\n",
    "    step = len(word_sim_dict) // (num_steps - 1)\n",
    "    step_set = set()\n",
    "    for i in range(0, num_steps - 1):\n",
    "        step_set.add(i * step)\n",
    "    step_set.add(len(word_sim_dict) - 1)\n",
    "    for i, d in enumerate(word_sim_dict.items()):\n",
    "        if i in step_set:\n",
    "            print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de68198-0ff9-4968-b9c7-ac2ba3102735",
   "metadata": {},
   "source": [
    "## germanet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d888b3ac-f95f-4f95-8143-4e7ad3be68c1",
   "metadata": {},
   "source": [
    "### relatedness_calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0755b-bcd6-4e0a-af76-1990c1cabf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "relatedness_calculator = PathBasedRelatedness(\n",
    "    germanet=germanet,\n",
    "    category=WordCategory.nomen,\n",
    ")\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    w1 = germanet.get_synsets_by_orthform(\"Trompete\").pop()\n",
    "    w2 = germanet.get_synsets_by_orthform(\"Flöte\").pop()\n",
    "    w3 = germanet.get_synsets_by_orthform(\"Haus\").pop()\n",
    "    w1_w2 = relatedness_calculator.leacock_chodorow(w1, w2)\n",
    "    w1_w3 = relatedness_calculator.leacock_chodorow(w1, w3)\n",
    "    print(w1_w2)\n",
    "    print(w1_w3)\n",
    "    w1_w2 = relatedness_calculator.simple_path(w1, w2)\n",
    "    w1_w3 = relatedness_calculator.simple_path(w1, w3)\n",
    "    print(w1_w2)\n",
    "    print(w1_w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c235f3-3176-4dc2-b0ff-e00d7bcd73d1",
   "metadata": {},
   "source": [
    "### get_average_synset_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e695aa5-03af-461a-b3b7-94303577444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_synset_similarity(word_1, word_2):\n",
    "    synset_list_1 = germanet.get_synsets_by_orthform(word_1)\n",
    "    synset_list_2 = germanet.get_synsets_by_orthform(word_2)\n",
    "    path_distance_list = []\n",
    "    for synset_1 in synset_list_1:\n",
    "        for synset_2 in synset_list_2:\n",
    "            try:\n",
    "                path_distance_list.append(relatedness_calculator.simple_path(synset_1, synset_2))\n",
    "            except:\n",
    "                pass\n",
    "    if len(path_distance_list) != 0:\n",
    "        average_path = sum(path_distance_list) / len(path_distance_list)\n",
    "        return average_path\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    print(get_average_synset_similarity(\"Frau\", \"Gattin\"))\n",
    "    print(get_average_synset_similarity(\"Frau\", \"Mann\"))\n",
    "    print(get_average_synset_similarity(\"Frau\", \"Küche\"))\n",
    "    print(get_average_synset_similarity(\"Frau\", \"Kind\"))\n",
    "    print(get_average_synset_similarity(\"Mann\", \"Kind\"))\n",
    "    print(get_average_synset_similarity(\"Frau\", \"Mathematik\"))\n",
    "    print(get_average_synset_similarity(\"Mann\", \"Mathematik\"))\n",
    "    print(get_average_synset_similarity(\"Frau\", \"Frau\"))\n",
    "    print(get_average_synset_similarity(\"Gattin\", \"Gattin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206167ad-cd38-456d-aa2d-685d7f908730",
   "metadata": {},
   "source": [
    "### get_all_words_of_germanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1330e4-c556-42fc-94da-641a04abf77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words_of_germanet():\n",
    "    lex_all_set = set()\n",
    "    for ss in germanet.synsets.values():\n",
    "        for lex in ss.lexunits:\n",
    "            lex_all_set.add(lex.orthform)\n",
    "    return lex_all_set\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    all_germanet_words_set = get_all_words_of_germanet()\n",
    "    print(len(all_germanet_words_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4453e-6e91-4024-bf41-ac67dd02ea80",
   "metadata": {},
   "source": [
    "### create_word_sim_germanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ef7c6-506e-467d-9402-c0e46aec99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_sim_germanet(word_a, word_set):\n",
    "    word_b_list = []\n",
    "    for word_b in word_set:\n",
    "        if word_a != word_b:\n",
    "            sim = get_average_synset_similarity(word_a, word_b)\n",
    "            if sim is not None:\n",
    "                word_b_list.append((word_b, sim))\n",
    "            else:\n",
    "                pass\n",
    "    word_b_list = sorted(word_b_list, key=lambda x: -x[1])\n",
    "    return {lex_b: dist for lex_b, dist in word_b_list}\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    sample_word = \"Tisch\"\n",
    "    word_sim_germanet_dict = create_word_sim_germanet(sample_word, all_germanet_words_set)\n",
    "    print_sample_of_related(word_sim_germanet_dict, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371d9ddb-6808-4e93-8850-8f61d88e7fe9",
   "metadata": {},
   "source": [
    "### create_lexeme_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259daf2-df62-40c3-a5b5-453ceba76889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lexeme_graph(limit=None, debug=False):\n",
    "    g = nx.Graph()\n",
    "    synset_list = list(germanet.synsets.values())\n",
    "    if limit is not None:\n",
    "        synset_list = synset_list[:limit]\n",
    "    for ss in synset_list:\n",
    "        if debug:\n",
    "            print(ss)\n",
    "        for ss_rel_key, ss_rel_set in ss.relations.items():\n",
    "            if debug:\n",
    "                print(\"\\t\", ss_rel_key)\n",
    "            for ss_rel in ss_rel_set:\n",
    "                if debug:\n",
    "                    print(\"\\t\\t\", ss_rel)\n",
    "                    print(\"\\t\\t\\t\", ss_rel.lexunits)\n",
    "                for lex_ss in ss.lexunits:\n",
    "                    for lex_ss_rel in ss_rel.lexunits:\n",
    "                        if \"GNROOT\" not in [lex_ss.orthform, lex_ss_rel.orthform]:\n",
    "                            g.add_edge(lex_ss.orthform, lex_ss_rel.orthform, label=ss.id + \"-\" + ss_rel.id)\n",
    "    return g\n",
    "\n",
    "\n",
    "# perhaps unnecessary function; thus disabled for now.\n",
    "# if ENABLE_TEST:\n",
    "#     g = create_lexeme_graph(limit=1000, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c9983-718c-4fac-be61-99a65ebb2bef",
   "metadata": {},
   "source": [
    "### plot_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a408a-aa62-433b-8366-e30756821b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(g, sub_node_list=None, traversal_limit=None):\n",
    "    if sub_node_list:\n",
    "        sub_node_rel_set = set()\n",
    "        for sub_node in sub_node_list:\n",
    "            if traversal_limit is not None:\n",
    "                sub_node_rel_dict = nx.single_source_shortest_path_length(g, sub_node, cutoff=traversal_limit)\n",
    "            else:\n",
    "                sub_node_rel_dict = nx.single_source_shortest_path_length(g, sub_node)\n",
    "            sub_node_rel_set.update(set(sub_node_rel_dict.keys()))\n",
    "        g = g.subgraph(sub_node_rel_set).copy()  # make a copy to avoid view issues\n",
    "    pos = nx.spring_layout(g, seed=42)\n",
    "\n",
    "    # edges\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_text = []\n",
    "    edge_label_x = []\n",
    "    edge_label_y = []\n",
    "    edge_label_text = []\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        x0, y0 = pos[u]\n",
    "        x1, y1 = pos[v]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "        edge_text.append(data.get(\"label\", \"\"))\n",
    "        # midpoint for edge label\n",
    "        edge_label_x.append((x0 + x1) / 2)\n",
    "        edge_label_y.append((y0 + y1) / 2)\n",
    "        edge_label_text.append(data.get(\"label\", \"\"))\n",
    "\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x,\n",
    "        y=edge_y,\n",
    "        line=dict(width=2, color=\"#888\"),\n",
    "        hoverinfo=\"text\",\n",
    "        text=edge_text,\n",
    "        mode=\"lines\",\n",
    "    )\n",
    "\n",
    "    # edge labels as separate trace\n",
    "    edge_label_trace = go.Scatter(\n",
    "        x=edge_label_x,\n",
    "        y=edge_label_y,\n",
    "        mode=\"text\",\n",
    "        text=edge_label_text,\n",
    "        textposition=\"middle center\",\n",
    "        hoverinfo=\"none\",\n",
    "        textfont=dict(color=\"black\", size=12),\n",
    "    )\n",
    "\n",
    "    # nodes\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    for node in g.nodes():\n",
    "        x, y = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        node_text.append(node)\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode=\"markers+text\",\n",
    "        text=node_text,\n",
    "        textposition=\"top center\",\n",
    "        hoverinfo=\"text\",\n",
    "        marker=dict(size=20, color=\"lightblue\", line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    )\n",
    "\n",
    "    # build figure\n",
    "    fig = go.Figure(\n",
    "        data=[edge_trace, edge_label_trace, node_trace],\n",
    "        layout=go.Layout(\n",
    "            width=1000,\n",
    "            height=1000,\n",
    "            title=\"Interactive Graph\",\n",
    "            showlegend=False,\n",
    "            hovermode=\"closest\",\n",
    "            margin=dict(b=20, l=5, r=5, t=40),\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        ),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# perhaps unnecessary function; thus disabled for now.\n",
    "# if ENABLE_TEST:\n",
    "#     plot_graph(g, sub_node_list=[\"unwirklich\"], traversal_limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a08172-bf6e-4278-984f-68f487589494",
   "metadata": {},
   "source": [
    "### get_all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5c011a-4afb-4ab1-be24-677d6c810aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_paths(g, l1, l2):\n",
    "    return list(nx.node_disjoint_paths(g, l1, l2))\n",
    "\n",
    "\n",
    "# perhaps unnecessary function; thus disabled for now.\n",
    "# if ENABLE_TEST:\n",
    "#     for p in get_all_paths(g, \"unwirklich\", \"fantastisch\"):\n",
    "#         print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d3bbac-d27c-4a8f-9fc4-bcd127a38b6f",
   "metadata": {},
   "source": [
    "## word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c8850-9b82-46ef-bab8-ab0cb0259269",
   "metadata": {},
   "source": [
    "### get_all_words_of_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663412e-009e-4525-9aa1-1866e78e1668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words_of_embeddings(embeddings_table, word_column_name):\n",
    "\n",
    "    query = SQL(\"SELECT {word_column_name} FROM {embeddings_table}\").format(\n",
    "        word_column_name=Identifier(word_column_name),\n",
    "        embeddings_table=Identifier(embeddings_table),\n",
    "    )\n",
    "    cursor.execute(query)\n",
    "    return cursor.fetchall()\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    words_embeddings = get_all_words_of_embeddings(\"word2vec__m4\", \"word\")\n",
    "    print(len(words_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38304bb2-7515-4bb0-8122-a14927649ba8",
   "metadata": {},
   "source": [
    "### get_word_embedding_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa72e45-6ca9-4278-a86e-0902dbb303ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding_similarity(\n",
    "    word_search, embeddings_table, word_column_name, embeddings_column_name, number_results=10, order_by_closest=True\n",
    "):\n",
    "\n",
    "    query = SQL(\n",
    "        dedent(\n",
    "            \"\"\"\\\n",
    "            SELECT * FROM get_related(\n",
    "                word_search := {word_search},\n",
    "                embeddings_table := {embeddings_table},\n",
    "                word_column_name := {word_column_name},\n",
    "                embeddings_column_name := {embeddings_column_name},\n",
    "                number_results := {number_results},\n",
    "                order_by_closest := {order_by_closest}\n",
    "            )\n",
    "            \"\"\"\n",
    "        )\n",
    "    ).format(\n",
    "        word_search=Literal(word_search),\n",
    "        embeddings_table=Literal(embeddings_table),\n",
    "        word_column_name=Literal(word_column_name),\n",
    "        embeddings_column_name=Literal(embeddings_column_name),\n",
    "        number_results=Literal(number_results),\n",
    "        order_by_closest=Literal(order_by_closest),\n",
    "    )\n",
    "    cursor.execute(query)\n",
    "    embeddings_table = cursor.fetchall()\n",
    "    return {word: similarity for word, similarity in embeddings_table}\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    word_sim_embedding_dict = get_word_embedding_similarity(\"tisch\", \"word2vec__m4\", \"word\", \"embedding\", None)\n",
    "    print_sample_of_related(word_sim_embedding_dict, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515c330-3d0b-44dc-9d95-a949558deaa8",
   "metadata": {},
   "source": [
    "# composite functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b6f5d-aa69-419b-b395-d28688038d87",
   "metadata": {},
   "source": [
    "## find_overlap_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6aa2b9-8dfe-46c4-9185-c3a0ae8c9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlap_words(words_germanet, words_embeddings):\n",
    "    words_embeddings = set([w[0].capitalize() for w in words_embeddings])\n",
    "    # words_germanet = get_all_words_of_germanet()\n",
    "    return words_embeddings.intersection(words_germanet)\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    overlap_word_set = find_overlap_words(all_germanet_words_set, words_embeddings)\n",
    "    print(len(overlap_word_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c57af8-c63e-4820-98d3-7da515bd5648",
   "metadata": {},
   "source": [
    "## filter_for_overlapping_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e6dab-0965-44d9-ad30-132ddaaa27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_for_overlapping_words(word_sim_germanet_dict, word_sim_embedding_dict):\n",
    "    word_embedding_set = {word.capitalize() for word in word_sim_embedding_dict.keys()}\n",
    "    common_word_set = word_embedding_set.intersection(set(word_sim_germanet_dict.keys()))\n",
    "    word_sim_germanet_filtered_dict = {}\n",
    "    for word, sim in word_sim_germanet_dict.items():\n",
    "        if word in common_word_set:\n",
    "            word_sim_germanet_filtered_dict[word] = sim\n",
    "    word_sim_embedding_filtered_dict = {}\n",
    "    for word, sim in word_sim_embedding_dict.items():\n",
    "        if word.capitalize() in common_word_set:\n",
    "            word_sim_embedding_filtered_dict[word] = sim\n",
    "    return word_sim_germanet_filtered_dict, word_sim_embedding_filtered_dict\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    print(len(word_sim_germanet_dict))\n",
    "    print(len(word_sim_embedding_dict))\n",
    "    word_sim_germanet_filtered_dict, word_sim_embedding_filtered_dict = filter_for_overlapping_words(\n",
    "        word_sim_germanet_dict,\n",
    "        word_sim_embedding_dict,\n",
    "    )\n",
    "    print(len(word_sim_germanet_filtered_dict))\n",
    "    print(len(word_sim_embedding_filtered_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd414f3-3db8-44ed-9610-291b779eaf45",
   "metadata": {},
   "source": [
    "## normalize_word_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73296b0f-0305-46c5-94a3-da3be35357fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_word_similarities(word_sim_dict):\n",
    "    sim_list = list(word_sim_dict.values())\n",
    "    sim_min = sim_list[0]\n",
    "    sim_max = sim_list[0]\n",
    "    for sim in sim_list[1:]:\n",
    "        if sim < sim_min:\n",
    "            sim_min = sim\n",
    "        if sim > sim_max:\n",
    "            sim_max = sim\n",
    "    scale = sim_max - sim_min\n",
    "    word_sim_normalized_dict = {}\n",
    "    for word_other, sim in word_sim_dict.items():\n",
    "        word_sim_normalized_dict[word_other] = (sim - sim_min) / scale\n",
    "    word_sim_normalized_dict\n",
    "    return word_sim_normalized_dict\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    word_sim_germanet_filtered_normalized_dict = normalize_word_similarities(word_sim_germanet_filtered_dict)\n",
    "    print_sample_of_related(word_sim_germanet_filtered_normalized_dict, 30)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    word_sim_embedding_filtered_normalized_dict = normalize_word_similarities(word_sim_embedding_filtered_dict)\n",
    "    print_sample_of_related(word_sim_embedding_filtered_normalized_dict, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2299c-6ed2-4498-b8c3-2dfaa8995a33",
   "metadata": {},
   "source": [
    "## randomize_sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c831d-d98c-4c2f-9182-a911d3d85300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_sim_dict(word_sim_dict):\n",
    "    sim_list = list(word_sim_dict.values())\n",
    "    random.shuffle(sim_list)\n",
    "    word_sim_randomized_dict = {}\n",
    "    for word, sim in zip(word_sim_dict.keys(), sim_list):\n",
    "        word_sim_randomized_dict[word] = sim\n",
    "    return word_sim_randomized_dict\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    word_sim_embedding_filtered_normalized_randomized_dict = randomize_sim_dict(word_sim_embedding_filtered_normalized_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b8ee78-89c5-4b73-88fd-4956eef0deb2",
   "metadata": {},
   "source": [
    "## calculate_sim_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3cb71-9ddd-4021-8858-3a9646df046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sim_diff(word_sim_germanet_dict, word_sim_embedding_dict, top_num=100):\n",
    "    sum_diff = 0\n",
    "    count_diff = 0\n",
    "    word_sim_list = list(word_sim_embedding_dict.items())\n",
    "    if top_num:\n",
    "        word_sim_list = word_sim_list[:top_num]\n",
    "    for word, sim_embedding in word_sim_list:\n",
    "        sim_germanet = word_sim_germanet_dict[word.capitalize()]\n",
    "        sum_diff += abs(sim_embedding - sim_germanet)\n",
    "        count_diff += 1\n",
    "    return sum_diff / count_diff\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    top_num = 1000\n",
    "    sim_diff = calculate_sim_diff(\n",
    "        word_sim_germanet_filtered_normalized_dict,\n",
    "        word_sim_embedding_filtered_normalized_dict,\n",
    "        top_num=top_num,\n",
    "    )\n",
    "    print(sim_diff)\n",
    "    sim_diff = calculate_sim_diff(\n",
    "        word_sim_germanet_filtered_normalized_dict,\n",
    "        word_sim_embedding_filtered_normalized_randomized_dict,\n",
    "        top_num=top_num,\n",
    "    )\n",
    "    print(sim_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c213ed13-eb0e-43a7-82f8-83d03e9c8c85",
   "metadata": {},
   "source": [
    "## create_word_sim_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff88b4-1b26-48c8-b1f3-e6f931a20903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_sim_dicts(word, all_germanet_words_set=None, print_num=None):\n",
    "    print(f\"{word=}\")\n",
    "    if all_germanet_words_set is None:\n",
    "        all_germanet_words_set = get_all_words_of_germanet()\n",
    "\n",
    "    # create sims\n",
    "    word_sim_germanet_dict = create_word_sim_germanet(word, all_germanet_words_set)\n",
    "    word_sim_embedding_dict = get_word_embedding_similarity(word.lower(), \"word2vec__m4\", \"word\", \"embedding\", None)\n",
    "\n",
    "    # filter on overlapping words\n",
    "    word_sim_germanet_filtered_dict, word_sim_embedding_filtered_dict = filter_for_overlapping_words(\n",
    "        word_sim_germanet_dict,\n",
    "        word_sim_embedding_dict,\n",
    "    )\n",
    "\n",
    "    # normalize\n",
    "    word_sim_germanet_filtered_normalized_dict = normalize_word_similarities(word_sim_germanet_filtered_dict)\n",
    "    if print_num:\n",
    "        print(\"word_sim_germanet_filtered_normalized_dict=\")\n",
    "        print_sample_of_related(word_sim_germanet_filtered_normalized_dict, print_num)\n",
    "    word_sim_embedding_filtered_normalized_dict = normalize_word_similarities(word_sim_embedding_filtered_dict)\n",
    "    if print_num:\n",
    "        print(\"word_sim_embedding_filtered_normalized_dict=\")\n",
    "        print_sample_of_related(word_sim_embedding_filtered_normalized_dict, print_num)\n",
    "\n",
    "    # create randomized null model\n",
    "    word_sim_embedding_filtered_normalized_randomized_dict = randomize_sim_dict(word_sim_embedding_filtered_normalized_dict)\n",
    "    if print_num:\n",
    "        print(\"word_sim_embedding_filtered_normalized_randomized_dict=\")\n",
    "        print_sample_of_related(word_sim_embedding_filtered_normalized_randomized_dict, print_num)\n",
    "\n",
    "    return (\n",
    "        word_sim_germanet_filtered_normalized_dict,\n",
    "        word_sim_embedding_filtered_normalized_dict,\n",
    "        word_sim_embedding_filtered_normalized_randomized_dict,\n",
    "    )\n",
    "\n",
    "\n",
    "if SET_TEST:\n",
    "    (\n",
    "        word_sim_germanet_dict,\n",
    "        word_sim_embedding_dict,\n",
    "        word_sim_embedding_randomized_dict,\n",
    "    ) = create_word_sim_dicts(\"Tisch\", print_num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed81a27-4730-471e-82ba-ac2175cf1c31",
   "metadata": {},
   "source": [
    "# analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67192a2-49c5-4ceb-a3f1-4b9e003c15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(diff_top_num=100, print_num=10, count_words=None):\n",
    "    all_germanet_words_set = get_all_words_of_germanet()\n",
    "    all_words_embeddings_list = get_all_words_of_embeddings(\"word2vec__m4\", \"word\")\n",
    "    overlap_word_set = find_overlap_words(all_germanet_words_set, all_words_embeddings_list)\n",
    "    word_list = list(overlap_word_set)\n",
    "    if count_words:\n",
    "        word_list = random.sample(sorted(word_list), count_words)\n",
    "    sim_diff_real_sum = 0\n",
    "    sim_diff_real_count = 0\n",
    "    sim_diff_random_sum = 0\n",
    "    sim_diff_random_count = 0\n",
    "    for word in word_list:\n",
    "        (\n",
    "            word_sim_germanet_dict,\n",
    "            word_sim_embedding_dict,\n",
    "            word_sim_embedding_randomized_dict,\n",
    "        ) = create_word_sim_dicts(word, all_germanet_words_set, print_num=print_num)\n",
    "        sim_diff_real = calculate_sim_diff(\n",
    "            word_sim_germanet_dict,\n",
    "            word_sim_embedding_dict,\n",
    "            top_num=diff_top_num,\n",
    "        )\n",
    "        print(f\"sim_diff_real={sim_diff_real}\")\n",
    "        sim_diff_random = calculate_sim_diff(\n",
    "            word_sim_germanet_dict,\n",
    "            word_sim_embedding_randomized_dict,\n",
    "            top_num=diff_top_num,\n",
    "        )\n",
    "        print(f\"sim_diff_random={sim_diff_random}\")\n",
    "\n",
    "        # total sums\n",
    "        sim_diff_real_sum += sim_diff_real\n",
    "        sim_diff_real_count += 1\n",
    "        sim_diff_random_sum += sim_diff_random\n",
    "        sim_diff_random_count += 1\n",
    "        print(\"----------------------------------------------------\")\n",
    "\n",
    "    sim_diff_real_avg = sim_diff_real_sum / sim_diff_real_count\n",
    "    sim_diff_random_avg = sim_diff_random_sum / sim_diff_random_count\n",
    "    print(f\"sim_diff_real_avg={sim_diff_real_avg}\")\n",
    "    print(f\"sim_diff_random_avg={sim_diff_random_avg}\")\n",
    "    return sim_diff_real_avg, sim_diff_random_avg\n",
    "\n",
    "\n",
    "sim_diff_real_avg, sim_diff_random_avg = analyse(diff_top_num=10, count_words=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d3462-fca3-47f4-a7de-92bbf19fcdd6",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d67b50-f373-43da-ab21-e0624ad112aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    word_sim_germanet_dict,\n",
    "    word_sim_embedding_dict,\n",
    "    word_sim_embedding_randomized_dict,\n",
    ") = create_word_sim_dicts(\"Tisch\", print_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd1f73-a2cd-4fa2-9b17-08592778abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(word_sim_germanet_dict.items()):\n",
    "    print(d)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37889e-2d01-441b-b75a-63eec569a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(word_sim_embedding_randomized_dict.items()):\n",
    "    print(d)\n",
    "    if i == 20:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
